{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac400c95",
   "metadata": {},
   "source": [
    "# <center>Streaming Twitter Data</center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b1c6e",
   "metadata": {},
   "source": [
    "## Twitter API\n",
    "- Streaming API\n",
    "- Ads API\n",
    "- Search API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87115352",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae0aad",
   "metadata": {},
   "source": [
    "### Streaming Endpoints\n",
    "- Filtered Streaming\n",
    "    - \n",
    "\n",
    "- Sampled Streaming\n",
    "    -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4671ed6",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e20699",
   "metadata": {},
   "source": [
    "## Filtered stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca0507",
   "metadata": {},
   "source": [
    ">This endpoint group allows users to listen for specific topics and events in real-time, monitor the conversation around competitions, understand how trends develop in real-time, and much more.\n",
    "\n",
    "> Developers can use the REST [rules endpoint](https://developer.twitter.com/en/docs/twitter-api/tweets/filtered-stream/api-reference/post-tweets-search-stream-rules) to add and remove rules to a persistent stream connection without needing to disconnect. These [rules](https://developer.twitter.com/en/docs/twitter-api/tweets/filtered-stream/integrate/build-a-rule) can be created with operators that match on Tweet attributes such as message keywords, hashtags, and URLs. Operators and rule clauses can be combined with boolean logic and parentheses to help refine the filter‚Äôs matching behavior.\n",
    "\n",
    "__Elevated access__\n",
    "- 25 rules per stream\n",
    "- 50 requests per 15 minutes when using the `POST` `/2/tweets/search/stream/rules` endpoint to add rules\n",
    "- Can only use the core operators when building your rule\n",
    "- Can build rules up to 512 characters in length\n",
    "- Cannot use the recovery and redundancy features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8fff3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e2c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from auth import environment_variables\n",
    "from filtered_streaming import (\n",
    "    spark_inst, get_rules, delete_all_rules,\n",
    "    set_rules, get_stream, main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13cca472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal uncomment the following line:\n",
    "#!export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "# To set your environment variables programatically uncomment the line below:\n",
    "environment_variables()\n",
    "bearer_token = os.getenv(\"BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c74d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": [{\"id\": \"1579952738519044098\", \"value\": \"cat has:images -grumpy\", \"tag\": \"cat pictures\"}, {\"id\": \"1579952738519044099\", \"value\": \"dog has:images\", \"tag\": \"dog pictures\"}], \"meta\": {\"sent\": \"2022-10-11T21:52:05.342Z\", \"result_count\": 2}}\n",
      "{'data': [{'id': '1579952738519044098', 'value': 'cat has:images -grumpy', 'tag': 'cat pictures'}, {'id': '1579952738519044099', 'value': 'dog has:images', 'tag': 'dog pictures'}], 'meta': {'sent': '2022-10-11T21:52:05.342Z', 'result_count': 2}}\n",
      "\n",
      "{\"meta\": {\"sent\": \"2022-10-11T21:52:05.556Z\", \"summary\": {\"deleted\": 2, \"not_deleted\": 0}}}\n",
      "{'meta': {'sent': '2022-10-11T21:52:05.556Z', 'summary': {'deleted': 2, 'not_deleted': 0}}}\n",
      "\n",
      "{\"data\": [{\"value\": \"cat has:images -grumpy\", \"tag\": \"cat pictures\", \"id\": \"1579953007508103169\"}, {\"value\": \"dog has:images\", \"tag\": \"dog pictures\", \"id\": \"1579953007508103170\"}], \"meta\": {\"sent\": \"2022-10-11T21:52:05.805Z\", \"summary\": {\"created\": 2, \"not_created\": 0, \"valid\": 2, \"invalid\": 0}}}\n",
      "{'data': [{'value': 'cat has:images -grumpy', 'tag': 'cat pictures', 'id': '1579953007508103169'}, {'value': 'dog has:images', 'tag': 'dog pictures', 'id': '1579953007508103170'}], 'meta': {'sent': '2022-10-11T21:52:05.805Z', 'summary': {'created': 2, 'not_created': 0, 'valid': 2, 'invalid': 0}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = get_rules()\n",
    "print(rules)\n",
    "print()\n",
    "\n",
    "delete = delete_all_rules(rules)\n",
    "print(delete)\n",
    "print()\n",
    "\n",
    "set = set_rules(delete)\n",
    "print(set)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660b8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953138949586944  ...  RT @finchbites: Silly goofy dog Pok√©mon https:...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953147350777856  ...  Paw Prints On My Heart Hoodie: Choose Your Cat...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953147123859457  ...  RT @nekoiroiro: „Éç„Ç≥ÂÆÖÊÄ•‰æø„Åß„Åô„ÄÇ\\n\\n#„Å≠„Åì #Áå´ #cat https:...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953153449263104  ...  RT @RozenMiyu: Dog Boi of @HornyMangos https:/...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953158847049729  ...  RT @jujunaught: Cat in heat https://t.co/89Id6...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953163393978368  ...  RT @sugatalus: cat found the yarn https://t.co...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953162630594560  ...  @metaversejoji I will say @dog_anarchy is now....\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953168783642624  ...  RT @bluish_gray_cat: Í∂ÅÎèÑÎ∂Ä Í∑∏ ÏÑ†Î∞∞.... https://t.co...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953169659854854  ...  RT @dailyvocaloidd: ‚òÖ hatsune miku ‚Ä¢ ‚ô™( ¬¥Œ∏ÔΩÄ)„Éé ...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953171795181569  ...  RT @cat_bot_kr: ÏöîÎ¶¨ÌïòÎäîÎç∞ Í≥†ÏñëÏù¥Í∞Ä ÏûêÍæ∏ Î∞©Ìï¥Ìï¥ÏÑú ÌôîÏû•Ïã§Ïóê Ïû†Ïãú Í∞ÄÎë¨ÎÜ®...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953174366289920  ...  RT @salaleyoo__: still2gether casts‚Äôs group pi...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953178250182659  ...  Cat ‚ÄúKneads Dough‚Äù While Watching Baking Video...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953180380893185  ...  RT @CitrisClove: Finished some owed, did this ...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953182570348544  ...  Custom dog ear outline, cat ear silhouette, pe...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953180385116161  ...  This is the piece I referenced! https://t.co/F...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953183220453376  ...  RT @GoodReddit: the hot dog guy lost it https:...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953187900911617  ...  RT @GoodReddit: the hot dog guy lost it https:...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953187762896896  ...  RT @LouisMaster_Pup: üê∂LITTLE DOG / BAD MASTERüê∂...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953188228067329  ...  RT @cat_56chan: „Å≠„Åò„Çå„Å¶„ÅÑ„Çã„Å≠„ÄÇ„Åä„ÇÑ„Åô„Åø„Äú https://t.co/FJL...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953194079510528  ...  RT @Shilo_Dog: There are three types of Deltar...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                               text\n",
      "0    1579953193299378177  ...  Â§ßËÉÜ„Å´ÂΩ±„ÇíÂ°ó„Çã„ÅÆË°ì https://t.co/Lxzi9U7Cwz\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                              text\n",
      "0    1579953190510166016  ...  Knife_cat.png #Splatoon3 https://t.co/X9W9jYO38W\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953198122815489  ...  RT @bunsenbernerbmd: Your timeline has been vi...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953202392625152  ...  RT @GoodReddit: the hot dog guy lost it https:...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953204036411394  ...  RT @jul_shii: dog and his dog https://t.co/KeR...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953201985384448  ...  RT @Max_Pericolo: @Number10cat One fox that La...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953207169941504  ...  RT @finchbites: Silly goofy dog Pok√©mon https:...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953205756035072  ...  RT @Irma_the_cat: Chillin‚Äô #CatsofTwitter http...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953214417678336  ...  RT @coolcatsociety: Which cat are you today?\\n...\n",
      "\n",
      "[1 rows x 3 columns]\n",
      "  edit_history_tweet_ids  ...                                               text\n",
      "0    1579953215281704961  ...  RT @fuwa_shop: „Åü„Åπ„Å£Â≠ê„Å©„ÅÜ„Å∂„Å§„ÅÆ„É´„Éº„É†„É©„Ç§„Éà„Åå„Åã„Çè„ÅÑ„ÅÑ‚Ä¶  „ÇÆ„É≥„Éì„Çπ„ÅåÁô∫Â£≤„Åô...\n",
      "\n",
      "[1 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/08-Misc/twitter-project/notebooks/filtered_streaming.py:104\u001b[0m, in \u001b[0;36mget_stream\u001b[0;34m(set)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get stream (HTTP \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    101\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m     )\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response_line \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response_line:\n\u001b[1;32m    106\u001b[0m         json_response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response_line)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:804\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 804\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode):\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    761\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py:575\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content):\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py:767\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/response.py:697\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_stream(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11343e5",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532f7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a69985",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark.streaming.kafka'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingContext\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#    Kafka\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkafka\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KafkaUtils\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#    json parsing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark.streaming.kafka'"
     ]
    }
   ],
   "source": [
    "#    Spark\n",
    "from pyspark import SparkContext\n",
    "#    Spark Streaming\n",
    "from pyspark.streaming import StreamingContext\n",
    "#    Kafka\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "#    json parsing\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696ca17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
